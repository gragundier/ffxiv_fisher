{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#import tensorflow_hub as hub\n",
    "from google.protobuf import text_format\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "gpu = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpu[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SHAPE=(224, 224)\n",
    "BATCH_SIZE=32\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2469 images belonging to 2 classes.\n",
      "Found 273 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1/255, \n",
    "    width_shift_range=.1,\n",
    "    height_shift_range=.1,\n",
    "    zoom_range=0.05,\n",
    "    channel_shift_range=0.05,\n",
    "    validation_split=0.1)\n",
    "train_data = image_generator.flow_from_directory(\n",
    "    \"/home/gragundier/Data/ffxiv_fisher2\",\n",
    "    target_size=IMAGE_SHAPE,\n",
    "    subset=\"training\",\n",
    "    class_mode=\"categorical\"\n",
    "    )\n",
    "validation_data = image_generator.flow_from_directory(\n",
    "    \"/home/gragundier/Data/ffxiv_fisher2\", \n",
    "    target_size=IMAGE_SHAPE,\n",
    "    subset=\"validation\",\n",
    "    class_mode=\"categorical\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_16 (Conv2D)           (None, 222, 222, 128)     3584      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 111, 111, 128)     0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 111, 111, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 109, 109, 32)      36896     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 54, 54, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 52, 52, 16)        4624      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 26, 26, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 26, 26, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 26, 26, 8)         1160      \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 5408)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               1384704   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 1,431,482\n",
      "Trainable params: 1,431,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    # The final convolution (same to make compute of reshape easier)\n",
    "    tf.keras.layers.Conv2D(8, (3,3), padding='same', activation='relu'),\n",
    "    #tf.keras.layers.MaxPooling2D(2,2),\n",
    "    #tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    \n",
    "    # Reshape to fit into LSTM/GRU\n",
    "    #tf.keras.layers.Reshape((26*26,8)),\n",
    "    #tf.keras.layers.LSTM(16, activation='tanh', use_bias = True, recurrent_dropout=0),\n",
    "    \n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "copied_metrics = [\n",
    "    tfma.metrics.ExampleCount(name='example_count'),\n",
    "    tfma.metrics.WeightedExampleCount(name='weighted_example_count'),\n",
    "    tf.keras.metrics.SparseCategoricalCrossentropy(\n",
    "        name='sparse_categorical_crossentropy'),\n",
    "    tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy'),\n",
    "    tf.keras.metrics.Precision(name='precision', top_k=1),\n",
    "    tf.keras.metrics.Precision(name='precision', top_k=3),\n",
    "    tf.keras.metrics.Recall(name='recall', top_k=1),\n",
    "    tf.keras.metrics.Recall(name='recall', top_k=3),\n",
    "    tfma.metrics.MultiClassConfusionMatrixPlot(\n",
    "        name='multi_class_confusion_matrix_plot'),\n",
    "]\n",
    "'''\n",
    "#https://www.tensorflow.org/tfx/model_analysis/metrics\n",
    "#metrics_specs = tfma.metrics.specs_from_metrics(metrics)\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='sgd', metrics=['accuracy', 'FalsePositives'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "78/78 [==============================] - 21s 264ms/step - loss: 0.5900 - accuracy: 0.6781 - false_positives: 374.6962 - val_loss: 0.5208 - val_accuracy: 0.6447 - val_false_positives: 97.0000\n",
      "Epoch 2/500\n",
      "78/78 [==============================] - 20s 251ms/step - loss: 0.3634 - accuracy: 0.8205 - false_positives: 219.7215 - val_loss: 0.7239 - val_accuracy: 0.6081 - val_false_positives: 107.0000\n",
      "Epoch 3/500\n",
      "78/78 [==============================] - 20s 251ms/step - loss: 0.2948 - accuracy: 0.8796 - false_positives: 154.4937 - val_loss: 0.6480 - val_accuracy: 0.6630 - val_false_positives: 92.0000\n",
      "Epoch 4/500\n",
      "78/78 [==============================] - 19s 249ms/step - loss: 0.2749 - accuracy: 0.8860 - false_positives: 135.0000 - val_loss: 0.7806 - val_accuracy: 0.6117 - val_false_positives: 106.0000\n",
      "Epoch 5/500\n",
      "78/78 [==============================] - 19s 246ms/step - loss: 0.2230 - accuracy: 0.9191 - false_positives: 102.5190 - val_loss: 0.6880 - val_accuracy: 0.6740 - val_false_positives: 89.0000\n",
      "Epoch 6/500\n",
      "78/78 [==============================] - 19s 247ms/step - loss: 0.2261 - accuracy: 0.9193 - false_positives: 103.3671 - val_loss: 0.8404 - val_accuracy: 0.6484 - val_false_positives: 96.0000\n",
      "Epoch 7/500\n",
      "78/78 [==============================] - 20s 252ms/step - loss: 0.1940 - accuracy: 0.9303 - false_positives: 84.8734 - val_loss: 0.6331 - val_accuracy: 0.6923 - val_false_positives: 84.0000\n",
      "Epoch 8/500\n",
      "78/78 [==============================] - 20s 250ms/step - loss: 0.1607 - accuracy: 0.9441 - false_positives: 73.4684 - val_loss: 0.6728 - val_accuracy: 0.6886 - val_false_positives: 85.0000\n",
      "Epoch 9/500\n",
      "78/78 [==============================] - 19s 248ms/step - loss: 0.1421 - accuracy: 0.9490 - false_positives: 65.1013 - val_loss: 0.6749 - val_accuracy: 0.7070 - val_false_positives: 80.0000\n",
      "Epoch 10/500\n",
      "78/78 [==============================] - 20s 251ms/step - loss: 0.1301 - accuracy: 0.9535 - false_positives: 61.7215 - val_loss: 0.6541 - val_accuracy: 0.7326 - val_false_positives: 73.0000\n",
      "Epoch 11/500\n",
      "78/78 [==============================] - 20s 248ms/step - loss: 0.1147 - accuracy: 0.9608 - false_positives: 52.6203 - val_loss: 0.8025 - val_accuracy: 0.7436 - val_false_positives: 70.0000\n",
      "Epoch 12/500\n",
      "78/78 [==============================] - 20s 251ms/step - loss: 0.1188 - accuracy: 0.9624 - false_positives: 42.4557 - val_loss: 0.3198 - val_accuracy: 0.8535 - val_false_positives: 40.0000\n",
      "Epoch 13/500\n",
      "78/78 [==============================] - 20s 253ms/step - loss: 0.0891 - accuracy: 0.9718 - false_positives: 36.6582 - val_loss: 0.2128 - val_accuracy: 0.9158 - val_false_positives: 23.0000\n",
      "Epoch 14/500\n",
      "78/78 [==============================] - 20s 252ms/step - loss: 0.0848 - accuracy: 0.9719 - false_positives: 34.6456 - val_loss: 0.2651 - val_accuracy: 0.8974 - val_false_positives: 28.0000\n",
      "Epoch 15/500\n",
      "78/78 [==============================] - 20s 260ms/step - loss: 0.0924 - accuracy: 0.9755 - false_positives: 26.8481 - val_loss: 0.1221 - val_accuracy: 0.9524 - val_false_positives: 13.0000\n",
      "Epoch 16/500\n",
      "78/78 [==============================] - 20s 254ms/step - loss: 0.0707 - accuracy: 0.9781 - false_positives: 31.4051 - val_loss: 0.1119 - val_accuracy: 0.9707 - val_false_positives: 8.0000\n",
      "Epoch 17/500\n",
      "78/78 [==============================] - 19s 246ms/step - loss: 0.0473 - accuracy: 0.9872 - false_positives: 17.9114 - val_loss: 0.1705 - val_accuracy: 0.9341 - val_false_positives: 18.0000\n",
      "Epoch 18/500\n",
      "78/78 [==============================] - 20s 254ms/step - loss: 0.0440 - accuracy: 0.9907 - false_positives: 14.7215 - val_loss: 0.0653 - val_accuracy: 0.9780 - val_false_positives: 6.0000\n",
      "Epoch 19/500\n",
      "78/78 [==============================] - 21s 266ms/step - loss: 0.0451 - accuracy: 0.9839 - false_positives: 19.7722 - val_loss: 0.1592 - val_accuracy: 0.9304 - val_false_positives: 19.0000\n",
      "Epoch 20/500\n",
      "78/78 [==============================] - 21s 263ms/step - loss: 0.0479 - accuracy: 0.9835 - false_positives: 17.1392 - val_loss: 0.0713 - val_accuracy: 0.9780 - val_false_positives: 6.0000\n",
      "Epoch 21/500\n",
      "78/78 [==============================] - 23s 290ms/step - loss: 0.0496 - accuracy: 0.9840 - false_positives: 18.5696 - val_loss: 0.1203 - val_accuracy: 0.9597 - val_false_positives: 11.0000\n",
      "Epoch 22/500\n",
      "78/78 [==============================] - 22s 287ms/step - loss: 0.0466 - accuracy: 0.9861 - false_positives: 17.0633 - val_loss: 0.0695 - val_accuracy: 0.9707 - val_false_positives: 8.0000\n",
      "Epoch 23/500\n",
      "78/78 [==============================] - 22s 278ms/step - loss: 0.0266 - accuracy: 0.9914 - false_positives: 10.1646 - val_loss: 0.2713 - val_accuracy: 0.8425 - val_false_positives: 43.0000\n",
      "Epoch 24/500\n",
      "78/78 [==============================] - 23s 293ms/step - loss: 0.0535 - accuracy: 0.9833 - false_positives: 18.0380 - val_loss: 0.0630 - val_accuracy: 0.9780 - val_false_positives: 6.0000\n",
      "Epoch 25/500\n",
      "78/78 [==============================] - 22s 276ms/step - loss: 0.0283 - accuracy: 0.9893 - false_positives: 11.8101 - val_loss: 0.1112 - val_accuracy: 0.9524 - val_false_positives: 13.0000\n",
      "Epoch 26/500\n",
      "78/78 [==============================] - 22s 281ms/step - loss: 0.0381 - accuracy: 0.9898 - false_positives: 15.5316 - val_loss: 0.0715 - val_accuracy: 0.9744 - val_false_positives: 7.0000\n",
      "Epoch 27/500\n",
      "78/78 [==============================] - 22s 280ms/step - loss: 0.0298 - accuracy: 0.9910 - false_positives: 12.9620 - val_loss: 0.1987 - val_accuracy: 0.9304 - val_false_positives: 19.0000\n",
      "Epoch 28/500\n",
      "78/78 [==============================] - 22s 287ms/step - loss: 0.0264 - accuracy: 0.9898 - false_positives: 13.6962 - val_loss: 0.0719 - val_accuracy: 0.9670 - val_false_positives: 9.0000\n",
      "Epoch 29/500\n",
      "78/78 [==============================] - 21s 273ms/step - loss: 0.0279 - accuracy: 0.9907 - false_positives: 10.3544 - val_loss: 0.0538 - val_accuracy: 0.9817 - val_false_positives: 5.0000\n",
      "Epoch 30/500\n",
      "78/78 [==============================] - 19s 247ms/step - loss: 0.0188 - accuracy: 0.9954 - false_positives: 7.0253 - val_loss: 0.1153 - val_accuracy: 0.9597 - val_false_positives: 11.0000\n",
      "Epoch 31/500\n",
      "78/78 [==============================] - 19s 245ms/step - loss: 0.0511 - accuracy: 0.9802 - false_positives: 19.1772 - val_loss: 0.0307 - val_accuracy: 0.9963 - val_false_positives: 1.0000\n",
      "Epoch 32/500\n",
      "78/78 [==============================] - 19s 245ms/step - loss: 0.0205 - accuracy: 0.9900 - false_positives: 10.4177 - val_loss: 0.0868 - val_accuracy: 0.9634 - val_false_positives: 10.0000\n",
      "Epoch 33/500\n",
      "78/78 [==============================] - 20s 249ms/step - loss: 0.0165 - accuracy: 0.9930 - false_positives: 7.7975 - val_loss: 0.0770 - val_accuracy: 0.9670 - val_false_positives: 9.0000\n",
      "Epoch 34/500\n",
      "78/78 [==============================] - 19s 246ms/step - loss: 0.0188 - accuracy: 0.9915 - false_positives: 9.8861 - val_loss: 0.1404 - val_accuracy: 0.9524 - val_false_positives: 13.0000\n",
      "Epoch 35/500\n",
      "78/78 [==============================] - 20s 251ms/step - loss: 0.0229 - accuracy: 0.9930 - false_positives: 7.1519 - val_loss: 0.0331 - val_accuracy: 0.9963 - val_false_positives: 1.0000\n",
      "Epoch 36/500\n",
      "78/78 [==============================] - 19s 249ms/step - loss: 0.0164 - accuracy: 0.9946 - false_positives: 6.1392 - val_loss: 0.0395 - val_accuracy: 0.9817 - val_false_positives: 5.0000\n",
      "Epoch 37/500\n",
      "78/78 [==============================] - 19s 241ms/step - loss: 0.0198 - accuracy: 0.9924 - false_positives: 8.8734 - val_loss: 0.0419 - val_accuracy: 0.9853 - val_false_positives: 4.0000\n",
      "Epoch 38/500\n",
      "78/78 [==============================] - 21s 267ms/step - loss: 0.0150 - accuracy: 0.9964 - false_positives: 5.2658 - val_loss: 0.0967 - val_accuracy: 0.9597 - val_false_positives: 11.0000\n",
      "Epoch 39/500\n",
      "78/78 [==============================] - 20s 257ms/step - loss: 0.0161 - accuracy: 0.9964 - false_positives: 4.5570 - val_loss: 0.0184 - val_accuracy: 1.0000 - val_false_positives: 0.0000e+00\n",
      "Epoch 40/500\n",
      "78/78 [==============================] - 22s 287ms/step - loss: 0.0166 - accuracy: 0.9966 - false_positives: 5.9620 - val_loss: 0.0482 - val_accuracy: 0.9780 - val_false_positives: 6.0000\n",
      "Epoch 41/500\n",
      "78/78 [==============================] - 20s 254ms/step - loss: 0.0213 - accuracy: 0.9934 - false_positives: 7.3038 - val_loss: 0.0191 - val_accuracy: 0.9963 - val_false_positives: 1.0000\n",
      "Epoch 42/500\n",
      "78/78 [==============================] - 20s 253ms/step - loss: 0.0109 - accuracy: 0.9983 - false_positives: 2.9114 - val_loss: 0.0676 - val_accuracy: 0.9817 - val_false_positives: 5.0000\n",
      "Epoch 43/500\n",
      "78/78 [==============================] - 20s 251ms/step - loss: 0.0154 - accuracy: 0.9968 - false_positives: 3.8481 - val_loss: 4.6594 - val_accuracy: 0.6630 - val_false_positives: 92.0000\n",
      "Epoch 44/500\n",
      "78/78 [==============================] - 20s 250ms/step - loss: 0.1884 - accuracy: 0.9402 - false_positives: 54.5190 - val_loss: 0.0372 - val_accuracy: 0.9853 - val_false_positives: 4.0000\n",
      "Epoch 45/500\n",
      "78/78 [==============================] - 20s 252ms/step - loss: 0.0171 - accuracy: 0.9962 - false_positives: 4.3671 - val_loss: 0.0923 - val_accuracy: 0.9524 - val_false_positives: 13.0000\n",
      "Epoch 46/500\n",
      "78/78 [==============================] - 20s 250ms/step - loss: 0.0189 - accuracy: 0.9935 - false_positives: 7.6709 - val_loss: 0.0126 - val_accuracy: 1.0000 - val_false_positives: 0.0000e+00\n",
      "Epoch 47/500\n",
      "11/78 [===>..........................] - ETA: 15s - loss: 0.0040 - accuracy: 1.0000 - false_positives: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-d333d0149e32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtensorboard_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#history = model.fit(train_data, epochs=500, validation_data = validation_data, verbose = 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = \"sequential_3\"\n",
    "t = time.time()\n",
    "log_dir = \"/home/gragundier/Data/logs/{}\".format(\"{}-{}\".format(model_name, t))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "history = model.fit(train_data, epochs=500, validation_data = validation_data, callbacks=[tensorboard_callback], verbose = 1)\n",
    "#history = model.fit(train_data, epochs=500, validation_data = validation_data, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/saved_models/1610732163/assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/saved_models/1610732163'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "export_path = \"/tmp/saved_models/{}\".format(int(t))\n",
    "model.save(export_path, save_format='tf')\n",
    "\n",
    "export_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
